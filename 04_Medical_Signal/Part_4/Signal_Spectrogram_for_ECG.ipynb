{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShuYuHuang/CMU_Course_signal/blob/main/04_Medical_Signal/Part_4/Signal_Spectrogram_for_ECG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAgWEtENTe_0"
      },
      "source": [
        "# Signall Processingå·¥å…·ä½¿ç”¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eVFZyj0Tkz8"
      },
      "source": [
        "ECG æˆ–è€…å…¶å®ƒè¨Šè™Ÿé€šå¸¸ç‚º1Dè¨Šè™Ÿ(å…ˆæ’é™¤channelé–“çš„é—œè¯æ€§)ï¼Œç„¡æ³•ç›´æ¥è¼¸å…¥2D CNNã€‚ååç¶²è·¯ä¸Šåˆåªæœ‰2D CNN çš„pre-train weightè©²å¦‚ä½•æ˜¯å¥½?\n",
        "\n",
        "\n",
        "é€™é‚Šæˆ‘å€‘å°‡ä»‹ç´¹ä½¿ç”¨pythonä¸€äº›è¨Šè™Ÿå·¥å…·ï¼Œå°è¨Šè™Ÿåšæ™‚é »åˆ†æï¼Œå¾—åˆ°2Dçš„æ™‚é »åœ–ï¼Œé€™æ¨£å°±èƒ½å¤ æœ‰CNNæ‰€å€šä»—çš„local connectivityæ€§è³ªï¼Œé©åˆä½¿ç”¨2D CNNã€‚æˆ‘å€‘é€™é‚Šæ‡‰ç”¨åœ¨ECGè¨Šè™Ÿçš„è™•è£¡ä¸Šï¼Œä¸éå…¶ä¸­å¾ˆå¤šæ¦‚å¿µèˆ‡å·¥å…·éƒ½å¯ä»¥ç”¨åœ¨å…¶ä»–è¨Šè™Ÿçš„è™•ç†ã€‚\n",
        "\n",
        "èª²ç¨‹åŒ…å«ä»¥ä¸‹å…§å®¹:\n",
        "* Up/Down Sampling\n",
        "* Fast Fourier Transform (FFT)\n",
        "* Short-Time Fourier Transform (STFT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBuA4UZbUqkD"
      },
      "source": [
        "# å‰ç½®æº–å‚™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygnYUkkVmtYg"
      },
      "outputs": [],
      "source": [
        "# For server or other condition that you might have to reinstall numba for librosa\n",
        "# %pip uninstall -y numba\n",
        "# %pip uninstall -y llvmlite\n",
        "# %conda install -y -c numba/label/dev llvmlite\n",
        "# %pip install git+https://github.com/numba/numba\n",
        "\n",
        "# For Colab, just install librosa\n",
        "%pip install librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEbeDIO3mtYi"
      },
      "outputs": [],
      "source": [
        "# For everyone\n",
        "%pip -q install transformers==4.30.0 datasets evaluate accelerate torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3EXnuslEqz3"
      },
      "outputs": [],
      "source": [
        "# å–å¾—ECGå–®æª”\n",
        "!wget https://github.com/ShuYuHuang/ai4ecg/releases/download/example_data/ecg_example.csv -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj4KfMyJEwQH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # å°å…¥pandaså¥—ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VijkLelD2k-k"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"ecg_example.csv\")  # è®€å–CSVæ–‡ä»¶\n",
        "sr = 500\n",
        "signal = data.values[:, 1:]  # å¾æ•¸æ“šä¸­æå–ä¿¡è™Ÿ\n",
        "signal.shape  # é¡¯ç¤ºsignalçš„å½¢ç‹€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEITsHC35Xpz"
      },
      "source": [
        "### Torchaudio.Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SR30ENqg5iRD"
      },
      "source": [
        "æˆ‘å€‘ä½¿ç”¨torchaudioåšç‚ºtorchåŸç”Ÿè™•ç†signal çš„æ–¹æ³•é›†\n",
        "- å¯ä»¥é‡å°toch tensorä½œç”¨\n",
        "- è¦–tensor deviceä½ç½®ï¼Œå¯ä»¥åœ¨ CPU åŠ GPU ä½œç”¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlDr7pPJ39r6"
      },
      "outputs": [],
      "source": [
        "# é€™é‚Šç‚ºäº†å¾Œé¢ä½¿ç”¨torchaudioçš„functionsï¼Œæˆ‘å€‘å°‡inputè½‰ç‚ºtensorä½¿ç”¨\n",
        "# torchaudio.transforms ä½œç”¨çš„è³‡æ–™shape: (BATCH,) ...,TIME\n",
        "# ç¸½ä¹‹æœ€å¾Œä¸€å€‹axiså¿…é ˆè¦æ˜¯æ™‚é–“ï¼Œå‰é¢å¦‚ä½•æ’åˆ—éƒ½ç„¡æ‰€è¬‚ï¼Œå› æ­¤ï¼Œæˆ‘å€‘å¾csvæª”è®€å–çš„è³‡æ–™é ˆç¶“étranspose\n",
        "x = torch.tensor(signal, dtype=torch.float32).transpose(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDu7v9Wa5i5x"
      },
      "outputs": [],
      "source": [
        "import torchaudio.transforms as T  # è¼‰å…¥è™•è£¡æ–¹æ³•é›†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABFrHj0_4Aqz"
      },
      "source": [
        "## Re-Sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMgCqPAl4h6D"
      },
      "source": [
        "Sampling rateçš„èª¿æ•´æ˜¯è™•ç†è¨Šè™Ÿé‡è¦çš„ä¸€ç’°ï¼Œè¦æ˜¯è¦å°‡å…©å€‹è¨Šè™Ÿç–ŠåŠ ï¼Œä½†ç™¼ç¾å…©è€…é›–ç„¶sampleæ•¸ç›¸åŒsampling rageå»ä¸ç›¸ç¬¦å‰‡æœƒæœ‰éŒ¯èª¤çš„ç–ŠåŠ æ•ˆæœã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYJK_Z2U4j_D"
      },
      "source": [
        "Re- samplingæœ‰å„ç¨®æ–¹æ³•ï¼Œå°è¨Šè™Ÿçš†æœ‰æ“¾å‹•ï¼Œè©³ç´°å¯åƒè€ƒtorchå®˜ç¶²åƒæ•¸```resampling_method```:\n",
        "https://pytorch.org/audio/stable/generated/torchaudio.transforms.Resample.html?highlight=resample#torchaudio.transforms.Resample\n",
        "\n",
        "é è¨­çš„å°±ä¸€èˆ¬è¨Šè™Ÿåˆ†æä¾†è¬›å¾ˆå¤ ç”¨äº†ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-4g_VUM4CLK"
      },
      "source": [
        "### Downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR2CDmVv5KOT"
      },
      "outputs": [],
      "source": [
        "# Downsample æ¸›å°‘sampling rate,ä¹Ÿæ¸›å°‘è³‡æ–™é»æ•¸\n",
        "downsample = T.Resample(orig_freq = sr, new_freq = sr//4)\n",
        "x_125 = downsample(x)\n",
        "print(x.shape, x_125.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDQteH_a6m5L"
      },
      "outputs": [],
      "source": [
        "# åŒæ¨£æ˜¯10ç§’éŒ„éŸ³ï¼Œåœ¨resampleå¾Œé»æ•¸æœƒè®Šå°‘\n",
        "print(len(x.T), len(x_125.T))\n",
        "# è‹¥æ˜¯éœ€æ±‚çš„sampling rateå‰›å¥½æ˜¯åŸæœ¬çš„å› æ•¸ï¼Œé‚£ä¹Ÿå¯ä»¥ç›´æ¥ä¾downsampleçš„å€ç‡åšsample\n",
        "x_125 = x[:, ::4]\n",
        "print(len(x.T), len(x_125.T))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9qKkFcQ9AYT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display as ldp\n",
        "\n",
        "\n",
        "\n",
        "# å¾waveplotä¸Šå¯ä»¥çœ‹åˆ°åœ¨ç¶“édownsampleå¾Œ æœ‰é»å¤±çœŸäº†\n",
        "ldp.waveshow(x[0, :int(0.5*sr)].numpy(), sr=sr)\n",
        "ldp.waveshow(x_125[0, :int(0.5*sr//4)].numpy(), sr=sr//4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiMYoKDu4HKL"
      },
      "source": [
        "### Upsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFcbCHhh7TUz"
      },
      "outputs": [],
      "source": [
        "# Upsample å¢åŠ sampling rate,ä¹Ÿå¢åŠ è³‡æ–™é»æ•¸\n",
        "upsample = T.Resample(orig_freq = sr, new_freq = sr*2)\n",
        "x_1000 = upsample(x)\n",
        "print(x.shape, x_1000.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1M5xN_L77D7"
      },
      "outputs": [],
      "source": [
        "# åœ¨upsampleæ™‚ä¸æœƒæœ‰å¤±çœŸçš„æƒ…æ³ï¼Œå› ç‚ºæ˜¯é¡ä¼¼åœ¨è³‡æ–™é–“æ’å€¼è£œå€¼\n",
        "ldp.waveshow(x[0, :int(0.5*sr)].numpy(), sr=sr)\n",
        "ldp.waveshow(x_1000[0, :int(0.5*sr*2)].numpy(), sr=sr*2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z5K7hcg4HQK"
      },
      "source": [
        "ä¸€èˆ¬ä¾†è¬›upsamplingéƒ½ä¸å­˜åœ¨æ¨™æº–ç­”æ¡ˆï¼Œå› ç‚ºå°±æ˜¯sampling rateä¸å¤ æ‰è¦è£œã€‚\n",
        "\n",
        "Upsamplingæœ¬èº«å¾Œä¾†åœ¨AIé ˜åŸŸä¹Ÿè®Šæˆä¸€å€‹è­°é¡Œï¼Œå«Super Resolutionï¼Œä½¿ç”¨è¨“ç·´å¥½çš„ç¥ç¶“ç¶²è·¯æ¨¡å‹ä¾†åšupsamplingå¢åŠ è§£æåº¦ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_POOkrU4HS1"
      },
      "source": [
        "## Fast Fourier Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRqwqVEI4HVj"
      },
      "source": [
        "åˆ†æè¨Šè™Ÿçš„æˆåˆ†æœ€å¸¸è¦‹çš„æ–¹å¼æ˜¯é »è­œåˆ†æï¼Œé€£çºŒè¨Šè™Ÿå¯ä»¥è—‰ç”±Fourier Transformå¾—åˆ°é »è­œï¼Œä¹Ÿå°±æ˜¯è¨Šè™Ÿåœ¨é »ç‡ä¸Šçš„åˆ†å¸ƒã€‚\n",
        "\n",
        "è€Œå°æ–¼æ•¸ä½è¨Šè™Ÿï¼Œæˆ‘å€‘å¯ä»¥è—‰ç”±Discrete Fourier Transformå¾—åˆ°é »è­œ\n",
        "$ğ—_kâ‰”\\sum\\limits_{ğ‘›=0}^{ğ‘âˆ’1}ğ‘¥_ğ‘› ğ‘’^{(âˆ’ğ‘—2ğœ‹ğ‘˜ğ‘›/ğ‘)}$\n",
        "\n",
        "<img src=https://hackmd.io/_uploads/SyMGrDWY3.png width=800>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXHGt0AB4WaT"
      },
      "source": [
        "Scipyæˆ–è€…å…¶ä»–å¥—ä»¶åŒ…æœ‰æä¾›ä¸€äº›æ–¹å¼åšå¿«é€Ÿçš„Discrete Fourier Transformï¼Œç¨±ç‚ºFast Fourier Transform(FFT)ã€‚\n",
        "\n",
        "è‹¥æ˜¯è¨Šè™Ÿåˆ†æå‰‡ç”¨Scipyå°±å¥½ï¼Œè‹¥æ˜¯è¦æ•´åˆåˆ°ç¥ç¶“ç¶²è·¯ä¸Šå¯èƒ½å°±å¾—ä½¿ç”¨Tensorflowæˆ–Pytorchå…§å»ºçš„fftã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t05NZuGX4T2q"
      },
      "outputs": [],
      "source": [
        "from scipy import fft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2DGvXyE-CPs"
      },
      "source": [
        "é€™é‚Šå› ç‚ºæˆ‘å€‘åšçš„æ˜¯é›¢æ•£çš„Fourierè½‰æ›(æ™‚é–“é»æ•¸ã€é »ç‡é»æ•¸)ï¼Œè‹¥è¦çœ‹åˆ°åŸæœ¬å–®ä½(seconds, Hz)å‰‡éœ€é€²è¡Œè½‰æ›ã€‚\n",
        "* æ™‚é–“: $t=n/f_s$ =>æ™‚é–“åˆ»åº¦ $\\Delta t=1/f_s$\n",
        "* é »ç‡: $f=k f_s/N$ =>é »ç‡åˆ»åº¦ $\\Delta f=f_s/N$\n",
        "\n",
        "Nç‚ºåƒèˆ‡FFTçš„æ™‚é–“é»æ•¸é‡ï¼Œ$f_s$å‰‡æ˜¯sampling rateã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wn-CnhUZ_xnt"
      },
      "source": [
        "**e.g. å‡è¨­æˆ‘å€‘æœ‰ä¸€æ®µè¨Šè™Ÿï¼Œå…¶æ¡æ¨£ç‡ç‚º 200Hzï¼Œæˆ‘å€‘ä½¿ç”¨ 500 é» FFT é€²è¡Œé »è­œåˆ†æï¼Œæˆ‘å€‘æƒ³è¦å–å¾— 0.2Hz~1.2Hz é€™å€‹é »æ®µçš„é »ç‡éŸ¿æ‡‰(é »è­œæ•¸å€¼)å¦‚ä½•é¸å–index?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDm2XzUVEPQh"
      },
      "source": [
        "é¦–å…ˆï¼Œæˆ‘å€‘éœ€è¦è¨ˆç®—é »è­œçš„æ¡æ¨£é–“éš”ã€‚\n",
        "\n",
        "é »ç‡åˆ»åº¦è¨ˆç®—è€ƒæ…®sampling rate $f_s = 200Hzï¼ŒFFTé»æ•¸N = 500$ï¼Œå› æ­¤ $\\Delta f = 200/500 = 0.4Hz$ã€‚\n",
        "\n",
        "å…¶æ¬¡ï¼Œæˆ‘å€‘éœ€è¦è¨ˆç®— 0.2Hz~1.2Hz é€™å€‹é »æ®µçš„index k å€¼ä¸”$k = f / \\Delta f $\n",
        "ï¼Œå› æ­¤ è¨ˆç®—æœ€ä½èˆ‡æœ€é«˜kå€¼ç‚ºï¼š\n",
        "\n",
        "- æœ€ä½ = 0.2Hz / 0.4Hz = 0.5\n",
        "- æœ€é«˜ = 1.2Hz / 0.4Hz = 3\n",
        "\n",
        "å› æ­¤ï¼Œæˆ‘å€‘éœ€è¦ç¯©å‡ºé »è­œä¸­ k å€¼ç‚º1\\~3çš„é »è­œï¼Œå¾—åˆ°[0.4, 0.8, 1.2] Hzçš„é »ç‡éŸ¿æ‡‰ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TknSFwfG-SRU"
      },
      "outputs": [],
      "source": [
        "signal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PqIM_01-ErM"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨scipy.fft.fftå¯ä»¥å°è¨Šè™Ÿåšfft\n",
        "#  'x' - è³‡æ–™\n",
        "#  'n' - FFTé»æ•¸ï¼Œé€šå¸¸ä¸æŒ‡å®šï¼Œé è¨­ç‚ºè³‡æ–™ç¸½é»æ•¸\n",
        "# è¨˜å¾—åšå®ŒFourier Transformå¾Œm, å‡ºä¾†éƒ½æ˜¯è¤‡æ•¸ (é è¨­ç‚ºcomplex64æ ¼å¼)\n",
        "# (ä¸ç®¡æ˜¯continuous/discrete/fast Fourier Transfor)\n",
        "N = len(signal)\n",
        "x_f = fft.fft(signal[:N,0])  # TIME => FREQUENCY (only FREQUENCY/2 range is valid)\n",
        "x_f.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E40CqfNRDQEO"
      },
      "outputs": [],
      "source": [
        "frequency = np.linspace(0, sr, N)\n",
        "max_f = 10  # è¨­å®šæƒ³çœ‹åˆ°çš„æœ€å¤§é »ç‡ (Hz)\n",
        "max_k = int(max_f*N/sr)  # è½‰æˆk\n",
        "\n",
        "# é€šå¸¸æˆ‘å€‘æ˜¯çœ‹é€™å€‹è¤‡æ•¸çš„magnitude, å–absoluteå°±å¯ä»¥åšåˆ°\n",
        "plt.plot(frequency[:max_k], abs(x_f[:max_k]))\n",
        "plt.xlabel(\"frequency(Hz)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-ySY9Zv-nUD"
      },
      "source": [
        "åœ¨é »è­œåœ–ä¸­æˆ‘å€‘å¯ä»¥çœ‹åˆ°è¼ƒç‚ºé«˜å³°çš„é»å°±è¡¨ç¤ºè¨Šè™Ÿæœ‰è¼ƒå¤šè©²é »ç‡æˆåˆ†ã€‚\n",
        "\n",
        "æˆ‘å€‘å¯ä»¥è©¦è‘—æŠŠåšé »è­œçš„æ™‚é–“ç¸®é»ä¸€é»ï¼Œä¾†çœ‹çœ‹æœ€å‰é¢ä¸€æ®µçš„é »è­œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGTzHZvx-oeM"
      },
      "outputs": [],
      "source": [
        "N1 = int(0*sr)\n",
        "N2 = int(5*sr)\n",
        "plt.plot(np.arange(N1, N2)/sr, signal[N1:N2, 0])\n",
        "plt.xlabel(\"time(s)\")\n",
        "plt.show()\n",
        "x_f2 = fft.fft(signal[N1:N2, 0])\n",
        "frequency2 = np.linspace(0, sr, N2-N1)\n",
        "max_k2 = int(max_f*(N2-N1)/sr)  # è½‰æˆk\n",
        "plt.plot(frequency2[:max_k2], abs(x_f2[:max_k2]))\n",
        "plt.xlabel(\"frequency(Hz)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9VPM-tw_dVk"
      },
      "source": [
        "æˆ‘å€‘å¯ä»¥çœ‹åˆ°è¼ƒå‰é¢ä¸€å°æ®µçš„é »è­œè·Ÿä¸€æ•´æ®µçš„å³°å‡ºç¾é »ç‡å·®ä¸å¤šï¼Œå› ç‚ºå¿ƒè·³éš¨è‘—æ™‚é–“æœ‰ç©©å®šçš„ç¯€å¥æ€§ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnyjTAXI_c08"
      },
      "outputs": [],
      "source": [
        "plt.plot(frequency[:max_k], abs(x_f[:max_k]))\n",
        "plt.plot(frequency2[:max_k2], abs(x_f2[:max_k2]))\n",
        "plt.xlabel(\"frequency(Hz)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf2R3m0WAjKc"
      },
      "source": [
        "æ“·å–èˆ‡æ•´æ®µå°æ¯”:\n",
        "* æ•´æ®µæ™‚é•·è¼ƒé•·ï¼Œå †ç©å‡ºçš„èƒ½é‡æ¯”è¼ƒé«˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F-9qQjiA9G0"
      },
      "source": [
        "## Short-Time Fourier Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJXz-x_IBAAs"
      },
      "source": [
        "è‹¥æ˜¯æƒ³çµ±è¨ˆå‡ºä¸€æ®µæ•´æ®µçš„é »ç‡åˆ†æï¼Œå‰‡é€™å€‹FFTå°±å¤ ç”¨äº†ï¼Œä½†é€šå¸¸æƒ³çŸ¥é“çš„æ˜¯åœ¨æ¯å€‹æ™‚é–“é»é »ç‡åˆ†å¸ƒé•·ä»€éº¼æ¨£å­å°±å¿…é ˆè¦åšæ™‚é »åˆ†æã€‚\n",
        "\n",
        "æ™‚é »åˆ†æä¸­æœ€å¸¸è¦‹çš„æ–¹å¼å°±æ˜¯Sort-Time Fourier Transform:\n",
        "1. Windowing\n",
        "2. å€‹åˆ¥åšé »è­œ\n",
        "\n",
        "å…¬å¼:\n",
        "\n",
        "$ğ‘‹[q,k] = \\sum\\limits_{ğ‘›^â€²=âŒˆâˆ’ğ‘/2âŒ‰}^{âŒˆğ‘/2âŒ‰âˆ’1}ğ‘¥[ğ‘›^â€²+ğ‘ğ»]ğ‘¤[ğ‘›^â€²] ğ‘’^\\frac{âˆ’ğ‘—2ğœ‹ğ‘˜ğ‘›^â€²}{ğ‘}$\n",
        "\n",
        "* q- æ¯å€‹windowçš„é›¢æ•£æ™‚é–“é»\n",
        "* k- é›¢æ•£é »ç‡é»\n",
        "* n'- åŸè¨Šè™Ÿçš„é›¢æ•£æ™‚é–“é»\n",
        "* N- windowå…§FFTé»æ•¸ï¼ŒåŒæ™‚æ˜¯window size\n",
        "* H- hop sizeï¼Œæ¯å€‹windowé›¢å¤šå°‘n'\n",
        "* w- windowing function\n",
        "* x- signal\n",
        "\n",
        "<img src=https://hackmd.io/_uploads/S1K7SPZK3.png width = 600>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP_Zaka9BUuc"
      },
      "source": [
        "æˆ‘å€‘é€™é‚Šä½¿ç”¨```torchaudio.transforms.Spectrogram```ä¾†åšæ™‚é »åˆ†æ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1jiReFK566G"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨T.Spectrogramå¯ä»¥å½¢æˆä¸€å€‹åšstftçš„function\n",
        "#  'n_fft' - FFTé»æ•¸ï¼ŒåŒæ™‚æ˜¯windowé•·åº¦ï¼Œé€™é‚Šä¸€å®šè¦æŒ‡å®šï¼Œé è¨­400ï¼Œå¯æ ¹æ“šè‡ªå·±æƒ³çœ‹åˆ°çš„é »ç‡ç¯„åœèª¿æ•´\n",
        "#  'hop_length' - æ¯å€‹windowé–“è¦è·³å¤šé•·\n",
        "#  'window_fn' - windowing functionï¼Œé è¨­æ˜¯ 'torch.hann_window'\n",
        "# å‡ºä¾†æ˜¯Spectrogram, typeç”±input typeæŒ‡å®š\n",
        "\n",
        "stft = T.Spectrogram(n_fft=128) # Calculate spectrogram with STFT\n",
        "S = stft(x)  # (BATCH,) CHANNELS, TIME => (BATCH,) CHANNELS, FREQUENCY, TIME\n",
        "S.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiF-a3GAB548"
      },
      "outputs": [],
      "source": [
        "# å¯ä»¥çœ‹å‡ºï¼Œæˆ‘å€‘ä½¿ç”¨STFTå¯ç”Ÿå‡ºä¸€å€‹K x Q çš„çŸ©é™£\n",
        "print(S.shape)\n",
        "print(type(S))\n",
        "print(S.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNFhNOI4Eoil"
      },
      "source": [
        "ä½¿ç”¨```librosa.display.specshow```å¯ä»¥ç•«å‡ºé »è­œåœ–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGaAO52FEtbs"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨librosa.display.specshowç•«å‡ºSpectrogram\n",
        "#  'data' - Spectrogram\n",
        "#  'sr' - sampling rate\n",
        "#  'x_axis' - x è»¸åˆ»åº¦å–®ä½\n",
        "#  'y_axis' - y è»¸åˆ»åº¦å–®ä½ï¼Œé è¨­ç‚º 'hz'ï¼Œè‹¥è¦ä½¿ç”¨log scaleå¯ä»¥ç”¨ 'log'\n",
        "#  'cmap' - color map\n",
        "#  'hop_length' - hop lengthï¼Œè¦è·Ÿè‘—å‰é¢\n",
        "#  'n_fft' - FFTé»æ•¸ï¼Œè¦è·Ÿè‘—å‰é¢\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(S[0].numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"hz\",\n",
        "             cmap=\"gray\")\n",
        "plt.colorbar(format=\"%+4.f\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ0hioDzGCnP"
      },
      "source": [
        "è‹¥å…¨åœ–æª¢è¦–å¯ä»¥çœ‹åˆ°æ‰€æœ‰åŒ…å«çš„é »ç‡ï¼Œä½†å…¶ä¸­Yè»¸çš„scaleæœ‰é»å¤ªå¤§ä½¿å¾—è¼ƒä½é »è¼ƒæœ‰è³‡è¨Šçš„éƒ¨åˆ†çœ‹ä¸è¦‹ï¼Œå¯ä»¥è½‰è€Œä½¿ç”¨log scale frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYpBJd6iGB_t"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(S[0].numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+4.f\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GiDitfkGR2E"
      },
      "source": [
        "çµæœå¦‚æœå°æ¯”ä¸å¤ æ˜é¡¯ï¼Œå¯ä»¥ä½¿ç”¨```librosa.power_to_db```è½‰æˆåˆ†è²ä¾†çœ‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps0hmmi8GUf9"
      },
      "outputs": [],
      "source": [
        "S_db = librosa.power_to_db(abs(S[0]).numpy()) # **\n",
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(S_db,\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.clim([-10, 10])  # **\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28R_q46IuAe"
      },
      "source": [
        "é€™é‚Šå°±æ˜¯æ›¹æ˜±è€å¸«è¬›éŸ³è¨Šè™•è£¡AIæ™‚çš„å‰ç½®æ­¥é©Ÿï¼Œfeature extractioné‚£ä¸€å¡Šåšçš„äº‹æƒ…\n",
        "\n",
        "<img src=https://hackmd.io/_uploads/BJ_UkJ3K2.png width=300>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy_A7qS5M9Tt"
      },
      "outputs": [],
      "source": [
        "# ä½¿ç”¨ power=None ä½¿å¾—Spectrogram è¿”å›å®Œæ•´complex numberé »è­œ torch.complex64\n",
        "stft = T.Spectrogram(n_fft=128, power=None) # Calculate spectrogram with STFT\n",
        "S_c = stft(x)  # (BATCH,) CHANNELS, TIME => (BATCH,) CHANNELS, FREQUENCY, TIME\n",
        "S_c.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVNeYyKROumu"
      },
      "source": [
        "å¯ä»¥ä½¿ç”¨å®ƒçš„ .real å«å‡ºå¯¦æ•¸éƒ¨åˆ†ã€ç”¨ .imag å«å‡ºè™›æ•¸éƒ¨åˆ†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvAg5LPlOIxp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(S_c[0].real.numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.clim([-10, 10])  # **\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWQVxtfcOaRO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(S_c[0].imag.numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.clim([-10, 10])  # **\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rk5jEWxP4Ve"
      },
      "source": [
        "ä½¿ç”¨ ```abs```å¯ä»¥å°‡åŸæœ¬complex numberçš„ amplitudeéƒ¨åˆ†æŠ“å‡ºä¾†ï¼Œå°±ç­‰æ–¼```power=1```çš„ä½œæ³•ï¼Œç¨±ç‚ºamplitude spectrum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9QEPPC6PrCW"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(abs(S_c[0]).numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.clim([-10, 10])  # **\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ27WOKEPZR2"
      },
      "source": [
        "ä½¿ç”¨ ```torch.angle```å¯ä»¥å°‡åŸæœ¬complex numberçš„ç›¸ä½ (å¯¦æ•¸èˆ‡è™›æ•¸çš„å¤¾è§’)æŠ“å‡ºä¾†ï¼Œå¾—åˆ°phase spectrum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ulHmx7FNsO2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "ldp.specshow(torch.angle(S_c[0]).numpy(),\n",
        "             n_fft=128,\n",
        "             hop_length=128//2,\n",
        "             sr=sr,\n",
        "             x_axis=\"s\",\n",
        "             y_axis=\"log\",\n",
        "             cmap=\"gray\")  # **\n",
        "plt.colorbar(format=\"%+2.f\")\n",
        "plt.clim([-10, 10])  # **\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJYzEJtNQmWf"
      },
      "source": [
        "è¨Šè™Ÿè™•ç†ä¸­æ¯”è¼ƒå¸¸çœ‹amplitude spectrumæˆ–è€…power spectrumï¼Œæ‰€ä»¥å¸¸ä»¥é€™å…©ç¨®åšç‚ºCNNçš„inputã€‚ä½†ä¹Ÿå¯å˜—è©¦å°‡phaseä¹ŸåŠ å…¥inputï¼Œå¢åŠ è³‡è¨Šã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAy_WfVR1W5W"
      },
      "source": [
        "## Augmentation  (é‚„åœ¨æƒ³è¦ä¸è¦åŠ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB_L_Hqmwy_j"
      },
      "outputs": [],
      "source": [
        "# from torchaudio.sox_effects import apply_effects_tensor\n",
        "# resample = 100\n",
        "# effects = []\n",
        "# if resample:\n",
        "#     effects.extend(\n",
        "#         [\n",
        "#             [\"lowpass\", f\"{resample // 2}\"],\n",
        "#             [\"rate\", f\"{resample}\"],\n",
        "#         ]\n",
        "#     )\n",
        "# x_, sr_ = apply_effects_tensor(x, sample_rate=500, effects=effects)\n",
        "# S = transform(x_).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tCvtYP4xXnL"
      },
      "outputs": [],
      "source": [
        "# plt.plot(np.linspace(0, 10, len(x_.T)), x_.T[:,0])\n",
        "# plt.plot(np.linspace(0, 10, len(x.T)), x.T[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-od3VQd1iV7"
      },
      "source": [
        "## Plot Spectrogram (é‚„åœ¨æƒ³è¦ä¸è¦æä¾›plotlyç‰ˆæœ¬)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuurEHMI2OnM"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "def plot_signal(signal, sr, start=0, end=None, labels=None, title=None):\n",
        "    # Visualizes signal data\n",
        "    # Args:\n",
        "    #  signal (list of array of int) - æ™‚é–“é»å°æ‡‰çš„è¨Šè™Ÿï¼Œåˆ—è¡¨å…§æ™‚é–“åºåˆ—æ•¸é‡ç‚ºDï¼Œæ¯ç­†è³‡æ–™é•·åº¦ç‚ºTï¼Œè‹¥éç‚ºåˆ—è¡¨å‰‡è½‰ç‚ºåˆ—è¡¨\n",
        "    #  start (int) - é–‹å§‹çš„è³‡æ–™åº(ç¬¬å¹¾ç­†)\n",
        "#  end (int) -   çµæŸç¹ªè£½çš„è³‡æ–™åº(ç¬¬å¹¾ç­†)\n",
        "    #  labels (list of strings)- å°æ–¼å¤šæ™‚é–“åºåˆ—æˆ–å¤šç¶­åº¦çš„æ¨™è¨»\n",
        "    #  title (string)- åœ–ç‰‡æ¨™é¡Œ\n",
        "\n",
        "    # è‹¥è³‡æ–™åªæœ‰ä¸€ç­†ï¼Œå‰‡è½‰ç‚ºlist\n",
        "    if type(signal) != list:\n",
        "        signal = [signal]\n",
        "\n",
        "    if not end:\n",
        "        end = len(signal[0])\n",
        "    time = (np.arange(len(signal[0]))/sr)[start:end]\n",
        "    if labels:\n",
        "        # è¨­ç«‹dictionary, è®“plotlyç•«è¨Šè™Ÿç·šæ™‚å¯ä»¥æ¨™è¨»label\n",
        "        dictionary = {\"time\": time}\n",
        "        for idx, l in enumerate(labels):\n",
        "            # æˆªæ–·è³‡æ–™ï¼Œä¿ç•™æƒ³çœ‹çš„éƒ¨åˆ†ï¼Œä¸¦åˆ†æ®µç´€éŒ„æ–¼dictionaryä¸­\n",
        "            dictionary.update({l: signal[idx][start:end]})\n",
        "        # ç•«è¨Šè™Ÿç·š\n",
        "        fig = px.line(dictionary,\n",
        "                      x=\"time\",\n",
        "                      y=list(dictionary.keys())[1:],\n",
        "                      width=1000,\n",
        "                      height=400,\n",
        "                      title=title)\n",
        "    else:\n",
        "        # ç•«è¨Šè™Ÿç·š\n",
        "        fig = px.line(x=time,\n",
        "                      y=signal,\n",
        "                      width=1000,\n",
        "                      height=400,\n",
        "                      title=title)\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liPi5b0d1xaW"
      },
      "outputs": [],
      "source": [
        "plot_signal(signal.T[1], sr=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vawOqj9l3V9w"
      },
      "source": [
        "# æ¨¡å‹è¨“ç·´"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3kCgVgm4QtL"
      },
      "source": [
        "ä½¿ç”¨èˆ‡é†«ç™‚å½±åƒåŒæ¨£çš„2D CNN model æˆ‘å€‘å¯ä»¥é‡å°è¨Šè™Ÿçš„é »è­œå»ºæ§‹classificationæ¨¡å‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHmyidpW3T05"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "# checkpoint = \"google/efficientnet-b6\"\n",
        "checkpoint = \"facebook/convnext-tiny-224\"\n",
        "# checkpoint = \"microsoft/beit-large-patch16-512\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYTya5VO4beq"
      },
      "outputs": [],
      "source": [
        "labels = ['N', 'O', 'A', '~']\n",
        "label2id = {c: c_idx for c_idx, c in enumerate(labels)}\n",
        "id2label = {str(c_idx): c for c_idx, c in enumerate(label2id)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMUk5NF84Oty"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2Oz5qVDEhqq"
      },
      "outputs": [],
      "source": [
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkTS_YIU6FX7"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "# mymetric = evaluate.combine([\n",
        "#     evaluate.load('accuracy'),\n",
        "#     evaluate.load('recall'),\n",
        "#     evaluate.load('precision'),\n",
        "#     evaluate.load('f1'),\n",
        "# ])\n",
        "mymetric = evaluate.load('accuracy')\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    return mymetric.compute(predictions=predictions.argmax(1), references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcU0iOrC41_F"
      },
      "source": [
        "å¯å…ˆå˜—è©¦å°‡ä¸€å€‹channelçš„spectrogramæ”¾å…¥modelã€‚\n",
        "\n",
        "æ³¨æ„é€™é‚Šè¦å°modelåšrepeatï¼Œç›´åˆ°æœ‰ä¸‰å€‹channelï¼Œå°ä¸Šmodelçš„RGBä¸‰å€‹channelã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T04avCMt6agC"
      },
      "outputs": [],
      "source": [
        "# é€™é‚Šè©¦è‘—æŠŠå…¶ä¸­ä¸€å€‹channelçš„Spectrogramä¸Ÿé€²Model\n",
        "# S çš„ 3 å€‹ axis: CH (12), FREQUENCY, TIME\n",
        "# S[0] çš„ 2 å€‹ axis: FREQUENCY, TIME\n",
        "# Model çš„ 4 å€‹ axis éœ€æ±‚: BATCH, CH (3), WIDTH, HEIGHT\n",
        "# => å‰é¢å¤šä¸€å€‹axis, åœ¨channelé‚£é‚Šéœ€è¦\n",
        "x = S[0].repeat(1, 3, 1, 1)\n",
        "with torch.no_grad():\n",
        "    logits = model(x.cuda()).logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCGso4LI7w1G"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtUT_T0u7I1h"
      },
      "source": [
        "åŒPart 2ï¼Œæˆ‘å€‘ä½¿ç”¨CinC2017æ¯”è³½è³‡æ–™é›†çš„ä¸€éƒ¨åˆ†ä¾†åšç‚ºè¨“ç·´è³‡æ–™\n",
        "\n",
        "åœ¨colabä¸Šè¦å…ˆä¸‹è¼‰è³‡æ–™é›†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFH56Pxc7yxP"
      },
      "outputs": [],
      "source": [
        "# download dataset\n",
        "!wget https://github.com/TA-aiacademy/CMU_Course/releases/download/signal_data/cinc_data.tar.gz\n",
        "!mkdir data\n",
        "!tar -xf cinc_data.tar.gz -C ./data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbhTBJO57ayh"
      },
      "source": [
        "ä¸‹é¢é‡å°é€™ç¨®spectrogramï¼Œæˆ‘å€‘åšä¸€å€‹ Dataset classã€‚\n",
        "\n",
        "å…¶ä¸­æœƒæœ‰äº›åƒæ•¸æ˜¯è€ƒé‡é€™ç­†è³‡æ–™è£¡é¢çš„ä¸€äº›å·²çŸ¥å…§å®¹ï¼Œä¾‹å¦‚æœ€å°é•·åº¦ï¼Œsampling rateç­‰ç­‰ã€‚\n",
        "\n",
        "åœ¨é€™å€‹ä¾‹å­ä¸­æˆ‘å€‘åªä½¿ç”¨å–®channelçš„spectrogramã€‚\n",
        "\n",
        "é‚£æˆ‘å€‘å·²çŸ¥é€™å€‹è³‡æ–™é›†ä¸­åªæœ‰ä¸€å€‹channelï¼Œæ‰€ä»¥åªè¦å–\"lead\"é€™å€‹channelå°±å¥½ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b89Y4pNxRCKK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio.transforms as T  # è¼‰å…¥è™•è£¡æ–¹æ³•é›†\n",
        "\n",
        "# Data SPECS:\n",
        "#   sampling rate: 300\n",
        "#   mininal length: ~9 seconds\n",
        "#   maximal length: ~60 seconds\n",
        "#   value range: -7360 ~ 7636\n",
        "class SpectogramDataset(Dataset):\n",
        "    def __init__(self,\n",
        "        data_root,\n",
        "        annot_file,\n",
        "        channel=\"lead\",\n",
        "        class_names=[\"N\", \"O\", \"A\", \"~\"],\n",
        "        n_fft=128,\n",
        "        min_len=300*9,\n",
        "        transforms=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_root (str): root directory of the dataset\n",
        "            annot_file (str): filename of the annotation file, \".json\" format\n",
        "            channel (list): target lead name\n",
        "            class_names (list): list of class names for mapping class name to class id\n",
        "            n_fft (int): point of fft for making spectrogram\n",
        "            min_len (int): length of the output signal, truncated from each full signal\n",
        "\n",
        "        \"\"\"\n",
        "        # Read the label file as list of dictionary\n",
        "        with open(annot_file,\"r\") as f:\n",
        "            self.labels=json.load(f)\n",
        "\n",
        "        # List the signal files\n",
        "        self.data_root = data_root\n",
        "        self.signal_paths = [\n",
        "            os.path.join(data_root, elem[\"csv\"]+\".csv\")\n",
        "            for elem in self.labels\n",
        "        ]\n",
        "\n",
        "        self.class_map = {n: i for i, n in enumerate(class_names)}\n",
        "\n",
        "        print(\"dataset class map: \", self.class_map)\n",
        "        # Set the target leads for the dataset\n",
        "        self.channel = channel\n",
        "        # Set the specs of the dataset\n",
        "        self.min_len = min_len\n",
        "        # Specify method of spectral analysis\n",
        "        self.spectral_analysis = T.Spectrogram(n_fft=n_fft)\n",
        "\n",
        "        # Import image processor if there is one\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_min_len(self):\n",
        "        # Calculate minimal length of signal\n",
        "        # in case you don't know it in advance\n",
        "        signal_len = [\n",
        "            len(self.load_file(file))\n",
        "            for file in self.signal_paths\n",
        "        ]\n",
        "        self.min_len = min(signal_len)\n",
        "        return self.min_len\n",
        "\n",
        "    def truncate(self, x):\n",
        "        # Truncate minimal length from full signal\n",
        "        start = np.random.randint(0, len(x)-self.min_len)  # get a start point of sampling\n",
        "        return x[start:start+self.min_len]\n",
        "\n",
        "    def load_file(self, file_name):\n",
        "        # Load singnal form file\n",
        "        return pd.read_csv(file_name)[self.channel].values\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get one singal and label specific to the given index\n",
        "        signal_path = self.signal_paths[idx]  # get data file path\n",
        "        signal = self.load_file(signal_path)  # load signal\n",
        "        signal = self.truncate(signal)  # get an equal length form file\n",
        "        class_name = self.labels[idx][\"choice\"]  # get label\n",
        "        class_id = self.class_map[class_name]  # map the label to number\n",
        "\n",
        "        # Put data, label into torch tensor\n",
        "        signal = torch.tensor(signal, dtype=torch.float32)\n",
        "        class_id = torch.tensor(class_id, dtype=torch.long)\n",
        "\n",
        "        # Get Spectrogram (repeat 3 times for the CNN model)\n",
        "        signal = self.spectral_analysis(signal).repeat(3, 1, 1)\n",
        "        signal = signal / signal.max() * 255\n",
        "\n",
        "        if self.transforms:\n",
        "            signal = self.transforms(signal)\n",
        "\n",
        "        return {'pixel_values': signal, 'label': class_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVHmSttxYty6"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import (\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    Resize,\n",
        ")\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (image_processor.size[\"shortest_edge\"], image_processor.size[\"shortest_edge\"])\n",
        "resize = Resize(size, antialias=True)\n",
        "transforms = Compose(\n",
        "    [\n",
        "        resize,\n",
        "        normalize,\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "train_ds = SpectogramDataset(\n",
        "    \"./data/csv_train\",\n",
        "    annot_file=\"./data/annot_train.json\",\n",
        "    transforms=transforms)\n",
        "test_ds = SpectogramDataset(\n",
        "    \"./data/csv_test\",\n",
        "    annot_file=\"./data/annot_test.json\",\n",
        "    transforms=transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOv1DTMtZLYZ"
      },
      "outputs": [],
      "source": [
        "# ç¢ºèªdatasetè®€å¾—å‡ºä¾†ï¼Œä»¥åŠä»–çš„shape\n",
        "item = next(iter(test_ds))\n",
        "item[\"pixel_values\"].shape # [batch, ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vqf6qVQ3KHbo"
      },
      "outputs": [],
      "source": [
        "x = item[\"pixel_values\"].numpy().transpose(1,2,0)\n",
        "x = (x-x.min())/(x.max()-x.min())\n",
        "plt.imshow(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I8TZ4AsAhwx"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_model_exercise\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    logging_first_step=True,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnahWkuVIKFg"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_collator = DefaultDataCollator()\n",
        "train_dl = DataLoader(train_ds, batch_size=32, collate_fn=data_collator)\n",
        "x = next(iter(train_dl))['pixel_values']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ngjDczKIdZq"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmooMS7VBA7o"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjU8hQbfHx5w"
      },
      "outputs": [],
      "source": [
        "from transformers.integrations import MLflowCallback\n",
        "trainer.remove_callback(MLflowCallback)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hge3C-FJJqj9"
      },
      "source": [
        "## Reference (å¥½åƒæ‡‰è©²ä¸Ÿäº›EEGçš„)\n",
        "* M. Mueller, Fundamentals of Music Processing, Springer 2015\n",
        "* å‰è¿°èª²æœ¬é™„Notebook- https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html\n",
        "* Librosaå®˜ç¶²- https://github.com/librosa/librosa\n",
        "* Acoustics for Musicians and Artists, by Miller Puckette, UCSD\n",
        "* Youtube ç†±é–€éŸ³è¨ŠAIèª²ç¨‹- https://github.com/musikalkemist/AudioSignalProcessingForML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q6jMy8BmtY5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}