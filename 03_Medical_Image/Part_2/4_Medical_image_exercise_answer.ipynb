{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efe5e3ea",
      "metadata": {
        "id": "efe5e3ea"
      },
      "source": [
        "# Exercise: Image classification with medical image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977a470d",
      "metadata": {
        "id": "977a470d"
      },
      "outputs": [],
      "source": [
        "# 安裝所需套件\n",
        "!pip install -q torchio\n",
        "!pip install -q transformers==4.30.0 datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282cf702",
      "metadata": {
        "id": "282cf702"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a8303e",
      "metadata": {
        "id": "b3a8303e"
      },
      "outputs": [],
      "source": [
        "# 匯入基本操作相關套件\n",
        "import torchio as tio\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 匯入 PyTorch 相關套件\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b471f921",
      "metadata": {
        "id": "b471f921"
      },
      "source": [
        "## Load dataset (chest x-ray)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922b2856",
      "metadata": {
        "id": "922b2856"
      },
      "source": [
        "#### Curated Chest X-Ray Image Dataset for COVID-19\n",
        "* resource: http://dx.doi.org/10.17632/9xkhgts2s6.1\n",
        "* dataset_url: https://github.com/TA-aiacademy/CMU_Course/releases/download/image_classification_data/Curated_Chest_X-Ray.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/TA-aiacademy/CMU_Course/releases/download/image_classification_data/Curated_Chest_X-Ray.zip\n",
        "!unzip -q Curated_Chest_X-Ray.zip"
      ],
      "metadata": {
        "id": "74bES0h-6Ule"
      },
      "id": "74bES0h-6Ule",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06b0ec92",
      "metadata": {
        "id": "06b0ec92"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Curated_Chest_X-Ray/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b06242c",
      "metadata": {
        "id": "1b06242c"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38fd32a8",
      "metadata": {
        "id": "38fd32a8"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset['train']\n",
        "valid_dataset = dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89990e32",
      "metadata": {
        "id": "89990e32"
      },
      "outputs": [],
      "source": [
        "item = next(iter(train_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c0066a",
      "metadata": {
        "id": "f6c0066a"
      },
      "outputs": [],
      "source": [
        "print(item['label'])\n",
        "item['image']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c1499f",
      "metadata": {
        "id": "48c1499f"
      },
      "outputs": [],
      "source": [
        "item['image'].size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a825b19",
      "metadata": {
        "id": "9a825b19"
      },
      "outputs": [],
      "source": [
        "train_dataset.features[\"label\"].names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f50304",
      "metadata": {
        "id": "28f50304"
      },
      "outputs": [],
      "source": [
        "labels = train_dataset.features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49293bb0",
      "metadata": {
        "id": "49293bb0"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c0eb16c",
      "metadata": {
        "id": "6c0eb16c"
      },
      "source": [
        "現在，按照標籤 id 轉換成名稱："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c982969",
      "metadata": {
        "id": "7c982969"
      },
      "outputs": [],
      "source": [
        "id2label[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4470e16d",
      "metadata": {
        "id": "4470e16d"
      },
      "source": [
        "## Preprocess\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00d3ecc5",
      "metadata": {
        "id": "00d3ecc5"
      },
      "source": [
        "接下來的步驟是載入指定模型使用的影像處理器，將影像處理成張量："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b374ed28",
      "metadata": {
        "id": "b374ed28"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "# checkpoint = \"google/vit-base-patch16-224-in21k\"  # model name\n",
        "# checkpoint = \"google/efficientnet-b6\"\n",
        "checkpoint = \"microsoft/cvt-13\"\n",
        "# checkpoint = \"google/mobilenet_v2_1.0_224\"\n",
        "# checkpoint = \"microsoft/resnet-50\"\n",
        "# checkpoint = \"facebook/convnext-tiny-224\"\n",
        "# checkpoint = \"facebook/convnext-base-224\"\n",
        "# # checkpoint = \"facebook/convnext-large-224\"\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52dc9df5",
      "metadata": {
        "id": "52dc9df5"
      },
      "outputs": [],
      "source": [
        "image_processor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0961e7ca",
      "metadata": {
        "id": "0961e7ca"
      },
      "source": [
        "---\n",
        "將影像進行轉換，使模型更具一般性以應付過擬合的情況。這裡會使用的 torchvision 中 transforms 的模組，但也能替換成其他適用的影像處理套件。\n",
        "\n",
        "將其調整影像大小以及隨機仿射處理，並使用影像的平均值和標準差進行標準化："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1a24a6",
      "metadata": {
        "id": "fe1a24a6"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Resize, RandomAffine, Compose, Normalize, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "# size = (image_processor.crop_size['height'], image_processor.crop_size['width'])\n",
        "\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = Compose([Resize(size),\n",
        "#                        RandomHorizontalFlip(),\n",
        "                       RandomAffine(degrees=10, scale=(0.9, 1.1)),\n",
        "                       ToTensor(),\n",
        "                       normalize])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62ff8e79",
      "metadata": {
        "id": "62ff8e79"
      },
      "source": [
        "接下來創建一個預處理函數，轉換並回傳影像的像素值作為模型的輸入："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e239152f",
      "metadata": {
        "id": "e239152f"
      },
      "outputs": [],
      "source": [
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c0af48",
      "metadata": {
        "id": "82c0af48"
      },
      "source": [
        "要在整個資料集上應用預處理函數，可以使用 Hugging Face 資料集的 [with_transform](https://huggingface.co/docs/datasets/v2.11.0/en/package_reference/main_classes#datasets.Dataset.with_transform) 方法。當載入資料集的一個元素時，轉換會即時套用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cc2b6e",
      "metadata": {
        "id": "80cc2b6e"
      },
      "outputs": [],
      "source": [
        "train_ds = train_dataset.with_transform(transforms)\n",
        "valid_ds = valid_dataset.with_transform(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f10612ba",
      "metadata": {
        "id": "f10612ba"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39ac692",
      "metadata": {
        "id": "a39ac692"
      },
      "outputs": [],
      "source": [
        "item = next(iter(train_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b2b5960",
      "metadata": {
        "id": "4b2b5960"
      },
      "outputs": [],
      "source": [
        "item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc6bf4f",
      "metadata": {
        "id": "0bc6bf4f"
      },
      "outputs": [],
      "source": [
        "print(item['label'])\n",
        "print(item['pixel_values'].size())\n",
        "plt.imshow(torch.permute(item['pixel_values'], (1, 2, 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14b3d992",
      "metadata": {
        "id": "14b3d992"
      },
      "source": [
        "現在使用 [DefaultDataCollator](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/data_collator#transformers.DefaultDataCollator) 創建一個批次樣本。與 Hugging face 裡 Transformers 的其他資料收集器不同，DefaultDataCollator 不會套用額外的預處理，例如填充（padding）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad7e3d4",
      "metadata": {
        "id": "3ad7e3d4"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6668010",
      "metadata": {
        "id": "d6668010"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a148c54a",
      "metadata": {
        "id": "a148c54a"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23fd478c",
      "metadata": {
        "id": "23fd478c"
      },
      "source": [
        "然後創建一個函數，將預測及標籤使用 [compute](https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/main_classes#evaluate.EvaluationModule.compute) 以計算準確度："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc78421e",
      "metadata": {
        "id": "bc78421e"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "349789ef",
      "metadata": {
        "id": "349789ef"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b10ee2e",
      "metadata": {
        "id": "9b10ee2e"
      },
      "source": [
        "現在已準備好開始訓練模型了！使用 [AutoModelForImageClassification](https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/auto#transformers.AutoModelForImageClassification) 載入模型。指定標籤的數量以及標籤的對應方式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a53e23e5",
      "metadata": {
        "id": "a53e23e5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a8eddc2",
      "metadata": {
        "id": "6a8eddc2"
      },
      "outputs": [],
      "source": [
        "# freeze layers without training\n",
        "for param in model.cvt.encoder.stages[:1].parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfcc7df",
      "metadata": {
        "id": "6bfcc7df"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d15dc00",
      "metadata": {
        "id": "5d15dc00"
      },
      "source": [
        "接著的階段，只剩以下三個步驟：\n",
        "\n",
        "1. 在 [TrainingArguments](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments) 中定義訓練的超參數。請務必留意資料集中未使用的資訊，設定 remove_unused_columns=False 可以防止被刪除未使用到的資訊！例如 image，這會導致無法獲得 pixel_values。另一個必需設定的參數是 output_dir，指定模型儲存的位置。通過設定 push_to_hub=True 將模型上傳至 Hub（需要登入 Hugging Face 才能上傳模型）。在每個 epoch 結束時，[Trainer](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer) 將評估準確性並儲存訓練模型。\n",
        "2. 將訓練參數、模型、資料集、預處理器、資料收集器以及計算評估指標函數傳遞給 [Trainer](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer)。\n",
        "3. 呼叫 [train](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer.train) 來微調模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdc1fca",
      "metadata": {
        "id": "2bdc1fca"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_model_exercise\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d1755a0",
      "metadata": {
        "id": "1d1755a0"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fee1e51",
      "metadata": {
        "id": "4fee1e51"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d470e3ec",
      "metadata": {
        "id": "d470e3ec"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f219ce",
      "metadata": {
        "id": "45f219ce"
      },
      "source": [
        "現在，微調後的模型以存放在指定路徑，並可使用它來進行推論！\n",
        "\n",
        "載入想要進行推論的影像："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90b8d44",
      "metadata": {
        "id": "a90b8d44"
      },
      "outputs": [],
      "source": [
        "test_dataset = dataset['test']\n",
        "image = test_dataset['image'][1]\n",
        "label = test_dataset['label'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d08457ec",
      "metadata": {
        "id": "d08457ec"
      },
      "outputs": [],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7fcf07",
      "metadata": {
        "id": "ae7fcf07"
      },
      "outputs": [],
      "source": [
        "id2label[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae647f0",
      "metadata": {
        "id": "6ae647f0"
      },
      "outputs": [],
      "source": [
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c0fe83",
      "metadata": {
        "id": "47c0fe83"
      },
      "source": [
        "使用微調後的模型進行推論最簡單的方法是在 pipline() 中設定。藉由指定的模型建構一個影像分類的 pipeline，然後將影像傳遞給它："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b543b90b",
      "metadata": {
        "id": "b543b90b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"image-classification\", model=\"my_model_exercise/checkpoint-500\")\n",
        "classifier(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae4de06d",
      "metadata": {
        "id": "ae4de06d"
      },
      "source": [
        "將輸入傳遞給模型，並回傳 logits（尚未經過 softmax）："
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49cadbbb",
      "metadata": {
        "id": "49cadbbb"
      },
      "source": [
        "載入影像處理器對影像進行預處理，並以 PyTorch 的張量型態回傳作為輸入："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67b2b3c",
      "metadata": {
        "id": "d67b2b3c"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "import torch\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"my_model_exercise/checkpoint-500\")\n",
        "inputs = image_processor(image.convert('RGB'), return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0895b855",
      "metadata": {
        "id": "0895b855"
      },
      "outputs": [],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64036c95",
      "metadata": {
        "id": "64036c95"
      },
      "source": [
        "將輸入傳遞給模型，並回傳 logits（尚未經過 softmax）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8a4804",
      "metadata": {
        "id": "5e8a4804"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"my_model_exercise/checkpoint-500\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d924d7b7",
      "metadata": {
        "id": "d924d7b7"
      },
      "outputs": [],
      "source": [
        "predicted_label = logits.argmax(-1).item()\n",
        "model.config.id2label[predicted_label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379d287a",
      "metadata": {
        "id": "379d287a"
      },
      "outputs": [],
      "source": [
        "model.config.id2label[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc29203",
      "metadata": {
        "id": "7fc29203"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}