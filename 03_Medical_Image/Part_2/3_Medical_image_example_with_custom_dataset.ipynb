{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "31409e07",
      "metadata": {
        "id": "31409e07"
      },
      "source": [
        "# Image classification with custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ed16c5",
      "metadata": {
        "id": "78ed16c5"
      },
      "source": [
        "以下將演示如何使用 huggingface 框架實現自定義載入資料集的方式，達到影像分類的結果。\n",
        "\n",
        "huggingface 的工作流程：\n",
        "![](https://hackmd.io/_uploads/SyirxbiP3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c39835",
      "metadata": {
        "id": "90c39835"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09bc9c34",
      "metadata": {
        "id": "09bc9c34"
      },
      "outputs": [],
      "source": [
        "# 安裝所需套件\n",
        "!pip -q install torchio\n",
        "!pip -q install transformers==4.30.0 datasets evaluate accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a65bf8",
      "metadata": {
        "id": "87a65bf8"
      },
      "outputs": [],
      "source": [
        "# 匯入基本操作相關套件\n",
        "import torchio as tio\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 匯入 PyTorch 相關套件\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c6bfcc",
      "metadata": {
        "id": "a5c6bfcc"
      },
      "source": [
        "## Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ba3d8c",
      "metadata": {
        "id": "68ba3d8c"
      },
      "source": [
        "* ### check data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload dataset NIH-3.zip\n",
        "!wget https://github.com/TA-aiacademy/CMU_Course/releases/download/image_classification_data/NIH-3.zip\n",
        "!unzip -q NIH-3.zip"
      ],
      "metadata": {
        "id": "kTyFjBh63Crl"
      },
      "id": "kTyFjBh63Crl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13cadaeb",
      "metadata": {
        "id": "13cadaeb"
      },
      "outputs": [],
      "source": [
        "# 蒐集資料集路徑\n",
        "train_dir = glob.glob(\"NIH-3/train/*/*.png\")\n",
        "valid_dir = glob.glob(\"NIH-3/valid/*/*.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba1bc3d",
      "metadata": {
        "id": "1ba1bc3d"
      },
      "outputs": [],
      "source": [
        "img = tio.ScalarImage(train_dir[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6103247d",
      "metadata": {
        "id": "6103247d"
      },
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a1c3d0",
      "metadata": {
        "id": "74a1c3d0"
      },
      "outputs": [],
      "source": [
        "img.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6cb1dc",
      "metadata": {
        "id": "eb6cb1dc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(img.data.permute((3, 2, 1, 0))[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d7a34c",
      "metadata": {
        "id": "58d7a34c"
      },
      "source": [
        "* ### check image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8a2d5dd",
      "metadata": {
        "id": "f8a2d5dd"
      },
      "outputs": [],
      "source": [
        "# 資料增強（data augmentation）\n",
        "transform = tio.Compose([\n",
        "    tio.RandomAffine(scales=0.1,\n",
        "                     degrees=10)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37a3af6d",
      "metadata": {
        "id": "37a3af6d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(transform(img).data.permute((3, 2, 1, 0))[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aa6a50e",
      "metadata": {
        "id": "6aa6a50e"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "# checkpoint = \"google/efficientnet-b6\"\n",
        "checkpoint = \"microsoft/cvt-13\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4cd740",
      "metadata": {
        "id": "ad4cd740"
      },
      "outputs": [],
      "source": [
        "image_processor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5135f148",
      "metadata": {
        "id": "5135f148"
      },
      "outputs": [],
      "source": [
        "image_processor(img.as_pil())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09cc430d",
      "metadata": {
        "id": "09cc430d"
      },
      "outputs": [],
      "source": [
        "image_processor(img.as_pil())['pixel_values'][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1566572d",
      "metadata": {
        "id": "1566572d"
      },
      "source": [
        "* ### Build custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21597c6",
      "metadata": {
        "id": "a21597c6"
      },
      "outputs": [],
      "source": [
        "class NIHDataset(Dataset):\n",
        "    def __init__(self, data_dir, label2id, image_processor=None, is_train=True):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = tio.Compose([\n",
        "            tio.RandomAffine(scales=0.1, degrees=10)\n",
        "        ])\n",
        "        self.label2id = label2id\n",
        "        self.image_processor = image_processor\n",
        "        self.is_train = is_train\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.data_dir[idx]\n",
        "        label = self.label2id[path.split('/')[-2]]\n",
        "        image = tio.ScalarImage(path)\n",
        "\n",
        "        # confirm the consistency of image dimension\n",
        "        if image.data.shape[0] != 1:  # channel_dim == 1 (grayscale)\n",
        "            image.set_data(torch.unsqueeze(image.data[0], 0))\n",
        "\n",
        "        # data augmentation\n",
        "        if self.is_train:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # preprocessing\n",
        "        if self.image_processor:\n",
        "            image = image_processor(image.as_pil())['pixel_values'][0]\n",
        "            return {'pixel_values': torch.tensor(image), 'label': label}\n",
        "        else:\n",
        "            image = tio.Resize((224, 224, 1))(image)\n",
        "            image = image.data.permute(0, 3, 2, 1).squeeze(0)  # (1, W, H, C)->(1, C, H, W)->(C, H, W)\n",
        "            image = image.repeat((3, 1, 1))  # gray to rgb\n",
        "            image = image.float()/255.\n",
        "            return {'pixel_values': image, 'label': label}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b43c8fc",
      "metadata": {
        "id": "6b43c8fc"
      },
      "outputs": [],
      "source": [
        "labels = [i.split('/')[-1] for i in sorted(glob.glob(\"NIH-3/train/*\"))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3c8566",
      "metadata": {
        "id": "ae3c8566"
      },
      "outputs": [],
      "source": [
        "label2id = {c: c_idx for c_idx, c in enumerate(labels)}\n",
        "id2label = {str(c_idx): c for c_idx, c in enumerate(label2id)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937d4697",
      "metadata": {
        "id": "937d4697"
      },
      "outputs": [],
      "source": [
        "label2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95302dbd",
      "metadata": {
        "id": "95302dbd"
      },
      "outputs": [],
      "source": [
        "id2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8237b920",
      "metadata": {
        "id": "8237b920"
      },
      "outputs": [],
      "source": [
        "train_dataset = NIHDataset(train_dir, label2id, image_processor)\n",
        "valid_dataset = NIHDataset(valid_dir, label2id, image_processor, is_train=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8de43ab",
      "metadata": {
        "id": "f8de43ab"
      },
      "source": [
        "* ### Check dataset item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "557f3d66",
      "metadata": {
        "id": "557f3d66"
      },
      "outputs": [],
      "source": [
        "iter_dataset = iter(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0736c1de",
      "metadata": {
        "id": "0736c1de"
      },
      "outputs": [],
      "source": [
        "item = next(iter_dataset)\n",
        "item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5470ca9c",
      "metadata": {
        "id": "5470ca9c"
      },
      "outputs": [],
      "source": [
        "plt.imshow(item['pixel_values'].permute((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d6820a0",
      "metadata": {
        "id": "7d6820a0"
      },
      "source": [
        "* ### Create data collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d383ce15",
      "metadata": {
        "id": "d383ce15"
      },
      "outputs": [],
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beea42c9",
      "metadata": {
        "id": "beea42c9"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66419e24",
      "metadata": {
        "id": "66419e24"
      },
      "source": [
        "在訓練過程中加入評估指標通常有助於評估模型的表現。可以使用 Hugging Face 的 [Evaluate](https://huggingface.co/docs/evaluate/index) 函式庫快速載入評估方法。在此任務上載入 [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) 指標（請參閱 Hugging Face 的 Evaluate [快速導覽](https://huggingface.co/docs/evaluate/a_quick_tour)，以了解如何載入和計算指標的詳細資訊）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a985d93d",
      "metadata": {
        "id": "a985d93d"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e99ed6b0",
      "metadata": {
        "id": "e99ed6b0"
      },
      "source": [
        "然後創建一個函數，將預測及標籤使用 [compute](https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/main_classes#evaluate.EvaluationModule.compute) 以計算準確度："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4023b90b",
      "metadata": {
        "id": "4023b90b"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bed0e3e4",
      "metadata": {
        "id": "bed0e3e4"
      },
      "source": [
        "## Build model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce077300",
      "metadata": {
        "id": "ce077300"
      },
      "source": [
        "現在已準備好開始訓練模型了！使用 [AutoModelForImageClassification](https://huggingface.co/docs/transformers/v4.28.1/en/model_doc/auto#transformers.AutoModelForImageClassification) 載入模型。指定標籤的數量以及標籤的對應方式："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4f5d7f1",
      "metadata": {
        "id": "f4f5d7f1"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True  # 預訓練模型的分類數量與自定義的資料集不同時使用\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0062efbe",
      "metadata": {
        "id": "0062efbe"
      },
      "outputs": [],
      "source": [
        "# freeze layers without training\n",
        "for param in model.cvt.encoder.stages[:1].parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8710943e",
      "metadata": {
        "id": "8710943e"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db3e6bda",
      "metadata": {
        "id": "db3e6bda"
      },
      "source": [
        "接著的階段，只剩以下三個步驟：\n",
        "\n",
        "1. 在 [TrainingArguments](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments) 中定義訓練的超參數。請務必留意資料集中未使用的資訊，設定 remove_unused_columns=False 可以防止被刪除未使用到的資訊！例如 image，這會導致無法獲得 pixel_values。另一個必需設定的參數是 output_dir，指定模型儲存的位置。通過設定 push_to_hub=True 將模型上傳至 Hub（需要登入 Hugging Face 才能上傳模型）。在每個 epoch 結束時，[Trainer](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer) 將評估準確性並儲存訓練模型。\n",
        "2. 將訓練參數、模型、資料集、預處理器、資料收集器以及計算評估指標函數傳遞給 [Trainer](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer)。\n",
        "3. 呼叫 [train](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer.train) 來微調模型。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370ea2bd",
      "metadata": {
        "id": "370ea2bd"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_cvt_model\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a61416a",
      "metadata": {
        "id": "9a61416a"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30754751",
      "metadata": {
        "id": "30754751"
      },
      "outputs": [],
      "source": [
        "from transformers.integrations import MLflowCallback\n",
        "trainer.remove_callback(MLflowCallback)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490a14f0",
      "metadata": {
        "id": "490a14f0"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "530d3a55",
      "metadata": {
        "id": "530d3a55"
      },
      "outputs": [],
      "source": [
        "train_loss = []\n",
        "valid_loss = []\n",
        "valid_acc = []\n",
        "for i in range(0, len(trainer.state.log_history)-1, 2):\n",
        "    train_loss.append(trainer.state.log_history[i]['loss'])\n",
        "    valid_loss.append(trainer.state.log_history[i+1]['eval_loss'])\n",
        "    valid_acc.append(trainer.state.log_history[i+1]['eval_accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a34be42",
      "metadata": {
        "id": "6a34be42"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(train_loss)), train_loss, label='train')\n",
        "plt.plot(range(len(valid_loss)), valid_loss, label='val')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross entropy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(len(valid_acc)), valid_acc)\n",
        "plt.title('Validation accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc51188f",
      "metadata": {
        "id": "fc51188f"
      },
      "outputs": [],
      "source": [
        "cfm_metric = evaluate.load(\"BucketHeadP65/confusion_matrix\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efbff792",
      "metadata": {
        "id": "efbff792"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54638b3a",
      "metadata": {
        "id": "54638b3a"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(test_dataset=valid_dataset)\n",
        "cm = cfm_metric.compute(predictions=np.argmax(outputs.predictions, axis=1),\n",
        "                        references=outputs.label_ids)['confusion_matrix']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b973c4e",
      "metadata": {
        "id": "7b973c4e"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 4))\n",
        "ax = sns.heatmap(cm, annot=True)\n",
        "ax.set(xlabel=\"prediction\", ylabel=\"label\")\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels, rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bc789a8",
      "metadata": {
        "id": "7bc789a8"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11a0e1e",
      "metadata": {
        "id": "e11a0e1e"
      },
      "source": [
        "現在，微調後的模型以存放在指定路徑，並可使用它來進行推論！\n",
        "\n",
        "載入想要進行推論的影像："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7a30476",
      "metadata": {
        "id": "d7a30476"
      },
      "outputs": [],
      "source": [
        "test_dir = glob.glob(\"NIH-3/test/*/*.png\")\n",
        "test_dataset = NIHDataset(test_dir, label2id, image_processor, is_train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc8d4104",
      "metadata": {
        "id": "cc8d4104"
      },
      "outputs": [],
      "source": [
        "test_loader = iter(DataLoader(test_dataset, batch_size=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6672ae33",
      "metadata": {
        "id": "6672ae33"
      },
      "outputs": [],
      "source": [
        "item = next(test_loader)\n",
        "test_x = item['pixel_values']\n",
        "test_y = item['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38269dbb",
      "metadata": {
        "id": "38269dbb"
      },
      "source": [
        "將輸入傳遞給模型，並回傳 logits（尚未經過 softmax）："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13f7ef8",
      "metadata": {
        "id": "a13f7ef8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"my_cvt_model/checkpoint-380/\")\n",
        "with torch.no_grad():\n",
        "    logits = model(test_x).logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4aab0e",
      "metadata": {
        "id": "2f4aab0e"
      },
      "outputs": [],
      "source": [
        "predicted_label = logits.argmax(-1).item()\n",
        "model.config.id2label[predicted_label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b948ab5f",
      "metadata": {
        "id": "b948ab5f"
      },
      "outputs": [],
      "source": [
        "model.config.id2label[test_y.item()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b1977a",
      "metadata": {
        "id": "64b1977a"
      },
      "source": [
        "* ### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c35ec7",
      "metadata": {
        "id": "b9c35ec7"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate(eval_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2138bb6e",
      "metadata": {
        "id": "2138bb6e"
      },
      "outputs": [],
      "source": [
        "outputs = trainer.predict(test_dataset=test_dataset)\n",
        "cm = cfm_metric.compute(predictions=np.argmax(outputs.predictions, axis=1),\n",
        "                        references=outputs.label_ids)['confusion_matrix']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18829231",
      "metadata": {
        "id": "18829231"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 4))\n",
        "ax = sns.heatmap(cm, annot=True)\n",
        "ax.set(xlabel=\"prediction\", ylabel=\"label\")\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_yticklabels(labels, rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd76294",
      "metadata": {
        "id": "4bd76294"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}